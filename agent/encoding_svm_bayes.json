{
  "metadata": {
    "proposito": "Codificación para SVM (clasificación de riesgo de deserción)",
    "tipo_encoding": "mixto (ordinal + one-hot)",
    "escalado_requerido": true,
    "scaler": "StandardScaler",
    "variable_objetivo": "riesgo_desercion"
  },
  
  "variable_objetivo": {
    "nombre": "riesgo_desercion",
    "descripcion": "Variable creada combinando desmotivación y consideración de abandono",
    "formula": "(desmotivacion_bin == 1) OR (considerado_abandonar_bin == 1)",
    "mapeo": {
      "0": "Sin riesgo de deserción - Estudiante estable",
      "1": "Con riesgo de deserción - Requiere intervención"
    },
    "codigo_creacion": "df['riesgo_desercion'] = ((df['desmotivacion_bin'] == 1) | (df['considerado_abandonar_bin'] == 1)).astype(int)",
    "nota": "Esta variable NO se usa como feature, es el TARGET a predecir"
  },
  
  "features_binarias": {
    "pregunta_4": {
      "nombre_variable": "dificultades_economicas",
      "nombre_feature": "dificultades_economicas_bin",
      "tipo_encoding": "binario",
      "mapeo": {
        "Sí": 1,
        "No": 0
      },
      "interpretacion_svm": "Feature binaria directa. Valor 1 empuja hacia clasificación de 'riesgo'.",
      "codigo": "df['dificultades_economicas_bin'] = df['dificultades_economicas'].map({'Sí': 1, 'No': 0})"
    },
    "pregunta_7": {
      "nombre_variable": "reprobo_materias",
      "nombre_feature": "reprobo_materias_bin",
      "tipo_encoding": "binario",
      "mapeo": {
        "Sí": 1,
        "No": 0
      },
      "interpretacion_svm": "Predictor fuerte de riesgo académico. Contribuye significativamente al hiperplano de separación.",
      "codigo": "df['reprobo_materias_bin'] = df['reprobo_materias'].map({'Sí': 1, 'No': 0})"
    }
  },
  
  "features_ordinales": {
    "pregunta_1": {
      "nombre_variable": "semestre",
      "nombre_feature": "semestre_ord",
      "tipo_encoding": "ordinal",
      "mapeo": {
        "1°-3°": 1,
        "4°-6°": 2,
        "7° o más": 3
      },
      "interpretacion_svm": "Captura etapa académica. SVM puede encontrar no-linealidad: riesgo alto en semestres iniciales y finales.",
      "codigo": "df['semestre_ord'] = df['semestre'].map({'1°-3°': 1, '4°-6°': 2, '7° o más': 3})"
    },
    "pregunta_8": {
      "nombre_variable": "apoyo_institucional",
      "nombre_feature": "apoyo_institucional_ord",
      "tipo_encoding": "ordinal",
      "mapeo": {
        "Nunca": 0,
        "Algunas veces": 1,
        "Siempre": 2
      },
      "interpretacion_svm": "Variable protectora. Valores altos contribuyen a clasificación 'sin riesgo'.",
      "direccion_efecto": "negativa (más apoyo = menos riesgo)",
      "codigo": "df['apoyo_institucional_ord'] = df['apoyo_institucional'].map({'Nunca': 0, 'Algunas veces': 1, 'Siempre': 2})"
    },
    "pregunta_9": {
      "nombre_variable": "satisfaccion_servicios",
      "nombre_feature": "satisfaccion_servicios_ord",
      "tipo_encoding": "ordinal",
      "mapeo": {
        "Muy insatisfecho/a": 0,
        "Insatisfecho/a": 1,
        "Satisfecho/a": 2,
        "Muy satisfecho/a": 3
      },
      "interpretacion_svm": "4 niveles de satisfacción. Variable protectora contra deserción.",
      "direccion_efecto": "negativa (más satisfacción = menos riesgo)",
      "codigo": "df['satisfaccion_servicios_ord'] = df['satisfaccion_servicios'].map({'Muy insatisfecho/a': 0, 'Insatisfecho/a': 1, 'Satisfecho/a': 2, 'Muy satisfecho/a': 3})"
    },
    "pregunta_10": {
      "nombre_variable": "actividades_extracurriculares",
      "nombre_feature": "actividades_extracurriculares_ord",
      "tipo_encoding": "ordinal",
      "mapeo": {
        "Nunca": 0,
        "Algunas veces": 1,
        "Sí, frecuentemente": 2
      },
      "interpretacion_svm": "Mide integración social. Participa en hiperplano pero con peso moderado.",
      "direccion_efecto": "negativa (más participación = menos riesgo)",
      "codigo": "df['actividades_extracurriculares_ord'] = df['actividades_extracurriculares'].map({'Nunca': 0, 'Algunas veces': 1, 'Sí, frecuentemente': 2})"
    }
  },
  
  "features_onehot": {
    "pregunta_5": {
      "nombre_variable": "empleo",
      "tipo_encoding": "one-hot",
      "razon": "SVM no debe asumir que 'tiempo completo' es '2x medio tiempo'. Son categorías distintas.",
      "categorias_originales": ["No", "Sí, medio tiempo", "Sí, tiempo completo"],
      "drop_first": true,
      "categoria_referencia": "No",
      "features_resultantes": {
        "empleo_medio_tiempo": {
          "descripcion": "1 si trabaja medio tiempo, 0 si no",
          "interpretacion": "Indica carga laboral moderada"
        },
        "empleo_tiempo_completo": {
          "descripcion": "1 si trabaja tiempo completo, 0 si no",
          "interpretacion": "Indica carga laboral alta - probable predictor de riesgo"
        }
      },
      "valores_combinaciones": {
        "No_trabaja": {"empleo_medio_tiempo": 0, "empleo_tiempo_completo": 0},
        "Medio_tiempo": {"empleo_medio_tiempo": 1, "empleo_tiempo_completo": 0},
        "Tiempo_completo": {"empleo_medio_tiempo": 0, "empleo_tiempo_completo": 1}
      },
      "codigo": "empleo_dummies = pd.get_dummies(df['empleo'], prefix='empleo', drop_first=True, dtype=int)\ndf = pd.concat([df, empleo_dummies], axis=1)"
    },
    "pregunta_6": {
      "nombre_variable": "impacto_laboral",
      "tipo_encoding": "one-hot",
      "razon": "Aunque parece ordinal, 'No afecta/No trabajo' es categóricamente diferente de 'Algo'. One-hot captura mejor estas diferencias.",
      "categorias_originales": ["No afecta / No trabajo", "Algo", "Sí, mucho"],
      "drop_first": true,
      "categoria_referencia": "No afecta / No trabajo",
      "features_resultantes": {
        "impacto_Algo": {
          "descripcion": "1 si el trabajo afecta algo el rendimiento, 0 si no",
          "interpretacion": "Impacto moderado trabajo-estudio"
        },
        "impacto_Si_mucho": {
          "descripcion": "1 si el trabajo afecta mucho el rendimiento, 0 si no",
          "interpretacion": "Impacto severo - fuerte predictor de riesgo"
        }
      },
      "valores_combinaciones": {
        "No_afecta": {"impacto_Algo": 0, "impacto_Si_mucho": 0},
        "Algo": {"impacto_Algo": 1, "impacto_Si_mucho": 0},
        "Si_mucho": {"impacto_Algo": 0, "impacto_Si_mucho": 1}
      },
      "codigo": "impacto_dummies = pd.get_dummies(df['impacto_laboral'], prefix='impacto', drop_first=True, dtype=int)\ndf = pd.concat([df, impacto_dummies], axis=1)",
      "nota": "Los nombres de columnas pueden variar según los espacios en las categorías originales. Usar df.columns para verificar."
    }
  },
  
  "lista_features_final": {
    "features_numericas": [
      "semestre_ord",
      "dificultades_economicas_bin",
      "reprobo_materias_bin",
      "apoyo_institucional_ord",
      "satisfaccion_servicios_ord",
      "actividades_extracurriculares_ord"
    ],
    "features_onehot": [
      "empleo_medio_tiempo",
      "empleo_tiempo_completo",
      "impacto_Algo",
      "impacto_Si_mucho"
    ],
    "total_features": 10,
    "nota": "Los nombres exactos de las columnas one-hot pueden variar. Verificar con df.columns después de get_dummies()"
  },
  
  "codigo_implementacion_completo": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n\n# 1. Crear variable objetivo\ndf['desmotivacion_bin'] = df['desmotivacion'].map({'Sí': 1, 'No': 0})\ndf['considerado_abandonar_bin'] = df['considerado_abandonar'].map({'Sí': 1, 'No': 0})\ndf['riesgo_desercion'] = ((df['desmotivacion_bin'] == 1) | (df['considerado_abandonar_bin'] == 1)).astype(int)\n\nprint(f'Distribución variable objetivo:')\nprint(df['riesgo_desercion'].value_counts())\nprint(f'Porcentaje en riesgo: {df[\"riesgo_desercion\"].mean()*100:.1f}%')\n\n# 2. Codificar features binarias y ordinales\ndf['dificultades_economicas_bin'] = df['dificultades_economicas'].map({'Sí': 1, 'No': 0})\ndf['reprobo_materias_bin'] = df['reprobo_materias'].map({'Sí': 1, 'No': 0})\ndf['semestre_ord'] = df['semestre'].map({'1°-3°': 1, '4°-6°': 2, '7° o más': 3})\ndf['apoyo_institucional_ord'] = df['apoyo_institucional'].map({'Nunca': 0, 'Algunas veces': 1, 'Siempre': 2})\ndf['satisfaccion_servicios_ord'] = df['satisfaccion_servicios'].map({'Muy insatisfecho/a': 0, 'Insatisfecho/a': 1, 'Satisfecho/a': 2, 'Muy satisfecho/a': 3})\ndf['actividades_extracurriculares_ord'] = df['actividades_extracurriculares'].map({'Nunca': 0, 'Algunas veces': 1, 'Sí, frecuentemente': 2})\n\n# 3. One-hot encoding\nempleo_dummies = pd.get_dummies(df['empleo'], prefix='empleo', drop_first=True, dtype=int)\nimpacto_dummies = pd.get_dummies(df['impacto_laboral'], prefix='impacto', drop_first=True, dtype=int)\ndf = pd.concat([df, empleo_dummies, impacto_dummies], axis=1)\n\nprint(f'\\nColumnas one-hot creadas:')\nprint(f'Empleo: {list(empleo_dummies.columns)}')\nprint(f'Impacto: {list(impacto_dummies.columns)}')\n\n# 4. Seleccionar features\nfeatures_numericas = ['semestre_ord', 'dificultades_economicas_bin', 'reprobo_materias_bin',\n                      'apoyo_institucional_ord', 'satisfaccion_servicios_ord', \n                      'actividades_extracurriculares_ord']\nfeatures_onehot = list(empleo_dummies.columns) + list(impacto_dummies.columns)\nall_features = features_numericas + features_onehot\n\nX = df[all_features]\ny = df['riesgo_desercion']\n\nprint(f'\\nShape final: X={X.shape}, y={y.shape}')\nprint(f'Features: {all_features}')\n\n# 5. Split y escalar\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f'\\nTrain: {X_train_scaled.shape}, Test: {X_test_scaled.shape}')\nprint(f'Distribución train: {pd.Series(y_train).value_counts().to_dict()}')\nprint(f'Distribución test: {pd.Series(y_test).value_counts().to_dict()}')",
  
  "hiperparametros_recomendados": {
    "C": {
      "descripcion": "Parámetro de regularización",
      "valores_probar": [0.1, 1, 10, 100],
      "interpretacion": "C bajo = más regularización (modelo simple), C alto = menos regularización (modelo complejo)"
    },
    "kernel": {
      "descripcion": "Tipo de kernel",
      "valores_probar": ["rbf", "linear"],
      "recomendacion": "rbf para relaciones no lineales, linear para interpretabilidad"
    },
    "gamma": {
      "descripcion": "Coeficiente del kernel (solo para rbf)",
      "valores_probar": ["scale", "auto", 0.001, 0.01, 0.1],
      "interpretacion": "Gamma bajo = decisión suave, gamma alto = decisión ajustada"
    },
    "class_weight": {
      "descripcion": "Pesos de clases para datos desbalanceados",
      "valores_probar": [null, "balanced"],
      "recomendacion": "'balanced' si hay desbalanceo significativo"
    }
  }
}
